{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV_O-VBxf9aC",
        "outputId": "251adb20-46ef-4bfe-8be8-6b7ac2e58d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy in /usr/local/lib/python3.10/dist-packages (2.5.42)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from dspy) (3.7.1)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from dspy) (0.0.8)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from dspy) (2.2.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from dspy) (5.5.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from dspy) (3.2.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from dspy) (5.6.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from dspy) (0.28.0)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.10/dist-packages (from dspy) (1.4.2)\n",
            "Requirement already satisfied: json-repair in /usr/local/lib/python3.10/dist-packages (from dspy) (0.30.3)\n",
            "Requirement already satisfied: litellm==1.51.0 in /usr/local/lib/python3.10/dist-packages (from dspy) (1.51.0)\n",
            "Requirement already satisfied: magicattr~=0.1.6 in /usr/local/lib/python3.10/dist-packages (from dspy) (0.1.6)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from dspy) (4.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dspy) (2.2.2)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.10/dist-packages (from dspy) (2.10.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dspy) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dspy) (2.32.3)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from dspy) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dspy) (4.66.6)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from dspy) (5.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (3.11.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (4.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (1.0.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (0.20.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio->dspy) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->dspy) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->dspy) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->dspy) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->dspy) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dspy) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dspy) (2.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->dspy) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (6.0.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->dspy) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy) (2.0.36)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy) (2024.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->dspy) (1.3.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (1.18.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm==1.51.0->dspy) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.51.0->dspy) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (0.22.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dspy) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->dspy) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade dspy openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "import dspy"
      ],
      "metadata": {
        "id": "fLCmsuApf_tN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_KEY = userdata.get('GPT_KEY')\n",
        "openai.api_key = OPENAI_KEY"
      ],
      "metadata": {
        "id": "ZpE8YIaxgaUw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_model = dspy.OpenAI(model='gpt-3.5-turbo',api_key = OPENAI_KEY)\n",
        "dspy.settings.configure(lm=openai_model)"
      ],
      "metadata": {
        "id": "7yeox8dd0DnV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlannerAgent(dspy.Signature):\n",
        "    \"\"\" You are a data analytics planner agent. Your task is to create a strategic plan for achieving a user-defined goal using the user defined goal and agents. You have access to two key inputs:\n",
        "          Data Agent Descriptions: A list of available data agents, each with a specific function or capability.\n",
        "          User-Defined Goal: The end objective that the user wants to accomplish using the available datasets and agents.\n",
        "\n",
        "        Task:\n",
        "          1. Develop a comprehensive plan to achieve the user-defined goal. You will determine which agents and datasets to use in a sequence that best achieves the goal.\n",
        "          2. If the goal appears infeasible or unclear, request further clarification or additional details from the user to refine the goal.\n",
        "\n",
        "        output format:\n",
        "          plan: Agent1 -> Agent2 -> Agent3 (e.g., Agent1 -> Agent3)\n",
        "          plan_desc: Provide a detailed explanation of why each agent is selected in sequence. Describe how each agent contributes to achieving the goal.\n",
        "          You are not required to use all the agents available in every response. Use only the relevant agents necessary for achieving the goal.\n",
        "\n",
        "    \"\"\"\n",
        "    Agent_desc = dspy.InputField(desc= \"The agents available in the system\")\n",
        "    goal = dspy.InputField(desc=\"The user defined goal \")\n",
        "    plan = dspy.OutputField(desc=\"The plan that would achieve the user defined goal\")\n",
        "    plan_desc= dspy.OutputField(desc=\"The reasoning behind the chosen plan\")\n",
        "\n",
        "class preprocessing_agent(dspy.Signature):\n",
        "    \"\"\" You are a Data Pre-processing Agent. Using Numpy and Pandas, create an EDA pipeline based on a user-defined goal and the available datasets. Clean the data (handle missing values, outliers, duplicates), transform it (scaling, encoding), and generate basic analysis (summary statistics, correlations, visualizations if needed). Output the Python code for the full pipeline, with brief comments explaining each step.\"\"\"\n",
        "    dataset = dspy.InputField(desc=\"Available datasets loaded in the system, use this df_name,columns  set df as copy of df_name\")\n",
        "    goal = dspy.InputField(desc=\"The user defined goal \")\n",
        "    code = dspy.OutputField(desc =\"The code that does the data preprocessing and introductory analysis\")\n",
        "\n",
        "class statistical_analytics_agent(dspy.Signature):\n",
        "    \"\"\" You are a Statistical Analytics Agent. Using Statsmodels, analyze the dataset to achieve the user-defined goal. Choose the appropriate statistical method (e.g., regression, hypothesis testing), preprocess the data if needed, and generate Python code for model fitting and analysis (e.g., p-values, confidence intervals). Include comments explaining each step.\"\"\"\n",
        "    dataset = dspy.InputField(desc=\"Available datasets loaded in the system, use this df_name,columns  set df as copy of df_name\")\n",
        "    goal = dspy.InputField(desc=\"The user defined goal for the analysis to be performed\")\n",
        "    commentary = dspy.OutputField(desc=\"The comments about what analysis is being performed\")\n",
        "    code = dspy.OutputField(desc =\"The code that does the statistical analysis using statsmodel\")\n",
        "\n",
        "class Data_Viz(dspy.Signature):\n",
        "    \"\"\"\n",
        "    You are an AI Agent using Plotly to create visualizations based on a user-defined goal and dataset. Identify the relevant data, generate the appropriate visualizations (e.g., bar charts, scatter plots), and output the Python code with necessary customizations. If required data is missing, state:\n",
        "    \"The dataset does not contain the necessary columns or information to generate the requested visualization.\"\n",
        "    \"\"\"\n",
        "    dataset = dspy.InputField(desc=\" Provides information about the data in the data frame. Only use column names and dataframe_name as in this context\")\n",
        "    goal = dspy.InputField(desc=\"user defined goal which includes information about data and chart they want to plot\")\n",
        "    commentary = dspy.OutputField(desc=\"The comments about what analysis is being performed\")\n",
        "    code= dspy.OutputField(desc=\"Plotly code that visualizes what the user needs according to the query & dataframe_index & styling_context\")\n",
        "\n",
        "class code_combiner_agent(dspy.Signature):\n",
        "    \"\"\" You are a Code Combine Agent. Combine Python code from multiple agents into a single, error-free script. Fix any syntax, logical, or compatibility issues, optimize for efficiency, and remove redundancy. Output the final, well-commented Python code. \"\"\"\n",
        "    agent_code_list =dspy.InputField(desc=\"A list of code given by each agent\")\n",
        "    code = dspy.OutputField(desc=\"Refined complete code base\")\n"
      ],
      "metadata": {
        "id": "cd7wewWQng97"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from httpx import Client\n",
        "\n",
        "# Save the original initialization\n",
        "original_client_init = Client.__init__\n",
        "\n",
        "# Patch to remove `proxies` argument\n",
        "def patched_client_init(self, *args, **kwargs):\n",
        "    kwargs.pop(\"proxies\", None)  # Remove proxies if passed\n",
        "    original_client_init(self, *args, **kwargs)\n",
        "\n",
        "Client.__init__ = patched_client_init\n"
      ],
      "metadata": {
        "id": "gd3tc3ee1zG_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data_analyst(dspy.Module):\n",
        "    def __init__(self, agents):\n",
        "        # Initialize agents and planner\n",
        "        self.agents = {}\n",
        "        self.agent_inputs = {}\n",
        "        self.agent_desc = []\n",
        "        i = 0\n",
        "        for a in agents:\n",
        "            name = a.__pydantic_core_schema__['schema']['model_name']\n",
        "            self.agents[name] = dspy.ChainOfThought(a)\n",
        "            self.agent_inputs[name] = {x.strip() for x in str(agents[i].__pydantic_core_schema__['cls']).split('->')[0].split('(')[1].split(',')}\n",
        "            self.agent_desc.append(str(a.__pydantic_core_schema__['cls']))\n",
        "            i += 1\n",
        "        self.planner = dspy.ChainOfThought(PlannerAgent)\n",
        "        self.combine = dspy.ChainOfThought(code_combiner_agent)\n",
        "\n",
        "\n",
        "    def forward(self, dataset, query):\n",
        "      dict_ = {}\n",
        "\n",
        "      dict_['Agent_desc'] = str(self.agent_desc)\n",
        "      dict_['goal'] = query\n",
        "\n",
        "      execution_plan = self.planner(\n",
        "            Agent_desc=dict_['Agent_desc'],\n",
        "            goal= query,\n",
        "            agents=[agent for agent in self.agents.values()]\n",
        "            )\n",
        "      print(execution_plan)\n",
        "\n",
        "      chunk_size = 100\n",
        "      chunks = np.array_split(dataset, len(dataset) // chunk_size + 1)\n",
        "      print(len(chunks))\n",
        "      docs = []\n",
        "      for chunk in chunks:\n",
        "        chunk_str = chunk.to_string()\n",
        "        dict_ = {\n",
        "            'dataset': chunk_str,\n",
        "            'goal': query,\n",
        "            'Agent_desc': str(self.agent_desc)\n",
        "        }\n",
        "        # agent_list = execution_plan.plan.split('->')\n",
        "        # code_combiner = \"\"\n",
        "        # Agent_outputs = {}\n",
        "        # for agent_name in agent_list:\n",
        "        #       name = agent_name.strip()\n",
        "        #       agent = self.agents[name]\n",
        "        #       result = agent(dataset=dict_['dataset'], agent_desc = dict_['Agent_desc'], goal= dict_['goal'])\n",
        "        #       Agent_outputs[name] = result\n",
        "        #       code_combiner += result.code\n",
        "        # combined_code = self.combine(agent_code_list = code_combiner)\n",
        "\n",
        "\n",
        "\n",
        "      agent_list = execution_plan.plan.split('->')\n",
        "      code_combiner = \"\"\n",
        "      Agent_outputs = {}\n",
        "      for agent_name in agent_list:\n",
        "            name = agent_name.strip()\n",
        "            agent = self.agents[name]\n",
        "            result = agent(dataset=dict_['dataset'], agent_desc = dict_['Agent_desc'], goal= dict_['goal'])\n",
        "            Agent_outputs[name] = result\n",
        "            code_combiner += result.code\n",
        "\n",
        "\n",
        "      combined_code = self.combine(agent_code_list = code_combiner)\n",
        "      return combined_code, Agent_outputs\n",
        "\n",
        "\n",
        "\n",
        "agents = [preprocessing_agent, statistical_analytics_agent, Data_Viz]\n",
        "\n",
        "Data_analyst_system = Data_analyst(agents)\n",
        "dataset = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")\n",
        "query = \"Visualizations on the dataset\"\n",
        "\n",
        "output,agent_outputs = Data_analyst_system.forward(dataset, query)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZNnPiCfpKon",
        "outputId": "0e09b649-e430-47c3-a923-61dddb4c8b4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
            " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
            " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
            "\n",
            " \t\tLearn more about the changes and how to migrate at\n",
            " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction(\n",
            "    rationale='produce the plan_desc. We need to start by preprocessing the dataset to clean and transform it, then move on to perform statistical analysis to identify patterns and relationships in the data. Finally, we can use data visualization to present the insights in a clear and visually appealing manner.',\n",
            "    plan='preprocessing_agent -> statistical_analytics_agent -> Data_Viz',\n",
            "    plan_desc='1. We will start by using the preprocessing_agent to clean the dataset, handle missing values, outliers, duplicates, and transform the data as needed.\\n2. Next, we will utilize the statistical_analytics_agent to perform statistical analysis on the preprocessed dataset to identify patterns and relationships that can be visualized.\\n3. Finally, we will use the Data_Viz agent to create visualizations'\n",
            ")\n",
            "31\n",
            "Prediction(\n",
            "    rationale='Combine the code snippets to load a dataset, handle missing values and duplicates, and create scatter plots using different visualization libraries.',\n",
            "    code='```python\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport plotly.express as px\\n\\n# Load the dataset\\ndf = pd.read_csv(\\'your_dataset.csv\\')\\n\\n# Check for missing values\\nmissing_values = df.isnull().sum()\\nprint(\"Missing values:\\\\n\", missing_values)\\n\\n# Handle missing values\\ndf = df.dropna()\\n\\n# Check for duplicates\\nduplicates = df.duplicated().sum()\\nprint(\"Number of duplicates:\", duplicates)\\n\\n# Handle duplicates\\ndf = df.drop_duplicates()\\n\\n# Scatter plot of median_income vs median_house'\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_outputs['preprocessing_agent'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsGqwwPzx1SE",
        "outputId": "e2efccd2-f030-4bd0-d8f2-001db66b0ad5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction(\n",
            "    rationale='create visualizations for the dataset. We will start by loading the dataset, handling missing values, outliers, duplicates, and then proceed to transform the data for visualization purposes.',\n",
            "    code='```python\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the dataset\\ndf_name = pd.read_csv(\\'your_dataset.csv\\')\\ndf = df_name.copy()\\n\\n# Check for missing values\\nmissing_values = df.isnull().sum()\\nprint(\"Missing values:\\\\n\", missing_values)\\n\\n# Handle missing values\\ndf = df.dropna()\\n\\n# Check for duplicates\\nduplicates = df.duplicated().sum()\\nprint(\"Number of duplicates:\", duplicates)\\n\\n# Handle duplicates\\ndf = df.drop_duplicates()'\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_outputs['statistical_analytics_agent']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTTvoXAmxQeX",
        "outputId": "5873f5d3-3f78-49f4-a3f8-0549c395d7ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    rationale='create visualizations for the dataset. We will start by loading the dataset and then use matplotlib and seaborn libraries to create various plots such as scatter plots, histograms, and box plots to visualize the data distribution and relationships between variables.',\n",
              "    commentary='We will use matplotlib and seaborn libraries to create visualizations for the dataset.',\n",
              "    code=\"```python\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the dataset\\ndf = pd.read_csv('dataset.csv')\\n\\n# Scatter plot of median_income vs median_house_value\\nplt.figure(figsize=(10, 6))\\nsns.scatterplot(x='median_income', y='median_house_value', data=df)\\nplt.title('Scatter plot of Median Income vs Median House Value')\\nplt\"\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_outputs['Data_Viz']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x56RwmoyF3f",
        "outputId": "836c887f-5a0b-417a-8fa2-0a69e2dda1de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    rationale='produce the code. We will create multiple visualizations to explore different aspects of the dataset such as the distribution of median house values, the relationship between median income and median house value, and the distribution of housing median age.',\n",
              "    commentary='The following code will generate multiple visualizations using Plotly to explore different aspects of the dataset.',\n",
              "    code=\"```python\\nimport plotly.express as px\\nimport pandas as pd\\n\\n# Create a DataFrame from the provided dataset\\ndata = {\\n    'longitude': [-118.32, -121.30, -117.69, -118.34, -121.92, -122.11, -117.65, -121.80, -122.66, -122.39],\"\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wbbfxcpyuqww"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}